{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report,accuracy_score,confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(r'C=\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\data_artifacts\\X_train_final_fe.csv')\n",
    "X_test = pd.read_csv(r'C=\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\data_artifacts\\X_test_final_fe.csv')\n",
    "y_train = pd.read_csv(r'C=\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\data_artifacts\\y_train_final.csv')\n",
    "y_test = pd.read_csv(r'C=\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\data_artifacts\\y_test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial)=\n",
    "    # Choose the algorithm to tune\n",
    "    classifier_name = trial.suggest_categorical(\n",
    "        'classifier', ['SVC', 'RandomForestClassifier'])\n",
    "\n",
    "    if classifier_name == 'SVC'=\n",
    "        # SVM hyperparameters with unique names\n",
    "        c = trial.suggest_float('svc_C', 0.1, 100, log=True)\n",
    "        kernel = trial.suggest_categorical('svc_kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "        gamma = trial.suggest_categorical('svc_gamma', ['scale', 'auto'])\n",
    "        class_weight = trial.suggest_categorical('svc_class_weight', [None, 'balanced'])\n",
    "\n",
    "        model = SVC(C=c, kernel=kernel, gamma=gamma, class_weight=class_weight, random_state=42)\n",
    "\n",
    "    elif classifier_name == 'RandomForestClassifier'=\n",
    "        # Random Forest hyperparameters with unique names\n",
    "        n_estimators = trial.suggest_int('rf_n_estimators', 50, 300)\n",
    "        max_depth = trial.suggest_int('rf_max_depth', 3, 20)\n",
    "        min_samples_split = trial.suggest_int('rf_min_samples_split', 2, 10)\n",
    "        min_samples_leaf = trial.suggest_int('rf_min_samples_leaf', 1, 10)\n",
    "        bootstrap = trial.suggest_categorical('rf_bootstrap', [True, False])\n",
    "        criterion = trial.suggest_categorical('rf_criterion', ['gini', 'entropy', 'log_loss'])\n",
    "        class_weight = trial.suggest_categorical('rf_class_weight', ['balanced', 'balanced_subsample', None])\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            bootstrap=bootstrap,\n",
    "            criterion=criterion,\n",
    "            class_weight=class_weight,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    # elif classifier_name == 'GradientBoostingClassifier'=\n",
    "    #     # Gradient Boosting hyperparameters with unique names\n",
    "    #     n_estimators = trial.suggest_int('gb_n_estimators', 50, 300)\n",
    "    #     learning_rate = trial.suggest_float('gb_learning_rate', 0.01, 1.0, log=True)\n",
    "    #     max_depth = trial.suggest_int('gb_max_depth', 3, 20)\n",
    "\n",
    "    #     model = GradientBoostingClassifier(\n",
    "    #         n_estimators=n_estimators,\n",
    "    #         learning_rate=learning_rate,\n",
    "    #         max_depth=max_depth,\n",
    "    #         random_state=42\n",
    "    #     )\n",
    "\n",
    "    # elif classifier_name == 'XGBClassifier'=\n",
    "    #     # XGBoost hyperparameters with unique names\n",
    "    #     n_estimators = trial.suggest_int('xgb_n_estimators', 50, 300)\n",
    "    #     learning_rate = trial.suggest_float('xgb_learning_rate', 0.01, 1.0, log=True)\n",
    "    #     max_depth = trial.suggest_int('xgb_max_depth', 3, 20)\n",
    "\n",
    "    #     model = XGBClassifier(\n",
    "    #         n_estimators=n_estimators,\n",
    "    #         learning_rate=learning_rate,\n",
    "    #         max_depth=max_depth,\n",
    "    #         random_state=42,\n",
    "    #         eval_metric='logloss'\n",
    "    #     )\n",
    "\n",
    "    # Perform cross-validation and return the mean accuracy\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-19 08:14:02,479] A new study created in memory with name: no-name-a6aaf7ec-825d-4de2-8454-a312f6265f9f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:14:08,697] Trial 0 finished with value: 0.7968751655480425 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 141, 'rf_max_depth': 5, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 2, 'rf_bootstrap': False, 'rf_criterion': 'log_loss', 'rf_class_weight': 'balanced'}. Best is trial 0 with value: 0.7968751655480425.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:14:30,053] Trial 1 finished with value: 0.8628757301811393 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 187, 'rf_max_depth': 17, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 6, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': None}. Best is trial 1 with value: 0.8628757301811393.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2026-01-19 08:14:54,819] Trial 2 finished with value: 0.8448749795247837 and parameters: {'classifier': 'SVC', 'svc_C': 1.4857774604057603, 'svc_kernel': 'linear', 'svc_gamma': 'auto', 'svc_class_weight': None}. Best is trial 1 with value: 0.8628757301811393.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:15:12,510] Trial 3 finished with value: 0.8636254958002718 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 108, 'rf_max_depth': 18, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 3 with value: 0.8636254958002718.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:15:31,456] Trial 4 finished with value: 0.8045009471340464 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 229, 'rf_max_depth': 3, 'rf_min_samples_split': 9, 'rf_min_samples_leaf': 2, 'rf_bootstrap': False, 'rf_criterion': 'log_loss', 'rf_class_weight': 'balanced'}. Best is trial 3 with value: 0.8636254958002718.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:15:55,571] Trial 5 finished with value: 0.8212509164036416 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 171, 'rf_max_depth': 19, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 5, 'rf_bootstrap': False, 'rf_criterion': 'gini', 'rf_class_weight': 'balanced'}. Best is trial 3 with value: 0.8636254958002718.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:16:00,937] Trial 6 finished with value: 0.8621254019916678 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 80, 'rf_max_depth': 13, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 7, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 3 with value: 0.8636254958002718.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2026-01-19 08:16:08,452] Trial 7 finished with value: 0.7226248819422704 and parameters: {'classifier': 'SVC', 'svc_C': 3.5265127270800933, 'svc_kernel': 'sigmoid', 'svc_gamma': 'scale', 'svc_class_weight': None}. Best is trial 3 with value: 0.8636254958002718.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2026-01-19 08:16:33,482] Trial 8 finished with value: 0.7892505559835779 and parameters: {'classifier': 'SVC', 'svc_C': 41.489650524582245, 'svc_kernel': 'rbf', 'svc_gamma': 'scale', 'svc_class_weight': 'balanced'}. Best is trial 3 with value: 0.8636254958002718.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2026-01-19 08:16:43,073] Trial 9 finished with value: 0.8448749795247837 and parameters: {'classifier': 'SVC', 'svc_C': 7.114790348311299, 'svc_kernel': 'linear', 'svc_gamma': 'scale', 'svc_class_weight': None}. Best is trial 3 with value: 0.8636254958002718.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:17:12,677] Trial 10 finished with value: 0.8211255100989346 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 291, 'rf_max_depth': 12, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': 'balanced_subsample'}. Best is trial 3 with value: 0.8636254958002718.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:17:17,754] Trial 11 finished with value: 0.8632504957885515 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 89, 'rf_max_depth': 20, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': None}. Best is trial 3 with value: 0.8636254958002718.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:17:20,665] Trial 12 finished with value: 0.8640004958119921 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 56, 'rf_max_depth': 20, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 12 with value: 0.8640004958119921.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:17:23,481] Trial 13 finished with value: 0.8621255895151142 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 58, 'rf_max_depth': 16, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 8, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 12 with value: 0.8640004958119921.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:17:28,325] Trial 14 finished with value: 0.8641255270698065 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 114, 'rf_max_depth': 8, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 14 with value: 0.8641255270698065.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:17:31,682] Trial 15 finished with value: 0.8138755254992974 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 50, 'rf_max_depth': 8, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': 'balanced_subsample'}. Best is trial 14 with value: 0.8641255270698065.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:17:36,888] Trial 16 finished with value: 0.8626256207846487 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 128, 'rf_max_depth': 8, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 4, 'rf_bootstrap': True, 'rf_criterion': 'gini', 'rf_class_weight': None}. Best is trial 14 with value: 0.8641255270698065.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:17:43,573] Trial 17 finished with value: 0.8646251832924486 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 143, 'rf_max_depth': 9, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 8, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2026-01-19 08:17:55,514] Trial 18 finished with value: 0.8378748699173294 and parameters: {'classifier': 'SVC', 'svc_C': 0.13954040452489774, 'svc_kernel': 'poly', 'svc_gamma': 'auto', 'svc_class_weight': 'balanced'}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:18:04,837] Trial 19 finished with value: 0.8640007302162999 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 181, 'rf_max_depth': 9, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 8, 'rf_bootstrap': False, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:18:13,209] Trial 20 finished with value: 0.8242509164974033 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 143, 'rf_max_depth': 10, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 7, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': 'balanced_subsample'}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:18:21,825] Trial 21 finished with value: 0.8640006364545766 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 186, 'rf_max_depth': 8, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 8, 'rf_bootstrap': False, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:18:32,937] Trial 22 finished with value: 0.8637504801772247 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 228, 'rf_max_depth': 10, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 8, 'rf_bootstrap': False, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:18:39,120] Trial 23 finished with value: 0.8598752143979002 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 167, 'rf_max_depth': 6, 'rf_min_samples_split': 9, 'rf_min_samples_leaf': 9, 'rf_bootstrap': False, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:18:47,780] Trial 24 finished with value: 0.8603756675951889 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 218, 'rf_max_depth': 14, 'rf_min_samples_split': 9, 'rf_min_samples_leaf': 6, 'rf_bootstrap': False, 'rf_criterion': 'gini', 'rf_class_weight': None}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:18:49,732] Trial 25 finished with value: 0.8637504332963631 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 118, 'rf_max_depth': 10, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 7, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2026-01-19 08:18:52,813] Trial 26 finished with value: 0.8391244324016888 and parameters: {'classifier': 'SVC', 'svc_C': 0.1051254299886186, 'svc_kernel': 'poly', 'svc_gamma': 'auto', 'svc_class_weight': 'balanced'}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:18:55,367] Trial 27 finished with value: 0.8597502769018087 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 152, 'rf_max_depth': 6, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 4, 'rf_bootstrap': False, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:18:59,044] Trial 28 finished with value: 0.8203755100754941 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 197, 'rf_max_depth': 9, 'rf_min_samples_split': 10, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': 'balanced_subsample'}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:00,550] Trial 29 finished with value: 0.7990001812414108 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 101, 'rf_max_depth': 6, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 8, 'rf_bootstrap': False, 'rf_criterion': 'gini', 'rf_class_weight': 'balanced'}. Best is trial 17 with value: 0.8646251832924486.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:04,631] Trial 30 finished with value: 0.8651253552045679 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 259, 'rf_max_depth': 11, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 30 with value: 0.8651253552045679.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:08,814] Trial 31 finished with value: 0.865000370827615 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 258, 'rf_max_depth': 11, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 30 with value: 0.8651253552045679.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:13,514] Trial 32 finished with value: 0.8650005583510613 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 270, 'rf_max_depth': 12, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 30 with value: 0.8651253552045679.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:17,780] Trial 33 finished with value: 0.8648755739741084 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 272, 'rf_max_depth': 14, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 30 with value: 0.8651253552045679.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:22,662] Trial 34 finished with value: 0.8637504801772247 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 277, 'rf_max_depth': 15, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 30 with value: 0.8651253552045679.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:27,580] Trial 35 finished with value: 0.8645005270815266 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 256, 'rf_max_depth': 12, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 30 with value: 0.8651253552045679.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:32,179] Trial 36 finished with value: 0.8438756670794995 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 257, 'rf_max_depth': 14, 'rf_min_samples_split': 9, 'rf_min_samples_leaf': 1, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': 'balanced'}. Best is trial 30 with value: 0.8651253552045679.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2026-01-19 08:19:33,580] Trial 37 finished with value: 0.7451248826454832 and parameters: {'classifier': 'SVC', 'svc_C': 70.48998910095523, 'svc_kernel': 'sigmoid', 'svc_gamma': 'auto', 'svc_class_weight': None}. Best is trial 30 with value: 0.8651253552045679.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:37,619] Trial 38 finished with value: 0.8651254020854294 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 256, 'rf_max_depth': 11, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'entropy', 'rf_class_weight': None}. Best is trial 38 with value: 0.8651254020854294.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:42,997] Trial 39 finished with value: 0.8652505739858287 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 298, 'rf_max_depth': 11, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': None}. Best is trial 39 with value: 0.8652505739858287.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2026-01-19 08:19:46,830] Trial 40 finished with value: 0.7857508996671742 and parameters: {'classifier': 'SVC', 'svc_C': 0.7048430201241145, 'svc_kernel': 'rbf', 'svc_gamma': 'scale', 'svc_class_weight': 'balanced'}. Best is trial 39 with value: 0.8652505739858287.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:51,798] Trial 41 finished with value: 0.8651254020854294 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 299, 'rf_max_depth': 11, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 10, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': None}. Best is trial 39 with value: 0.8652505739858287.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:19:57,017] Trial 42 finished with value: 0.8655005427397344 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 300, 'rf_max_depth': 11, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': None}. Best is trial 42 with value: 0.8655005427397344.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:20:02,049] Trial 43 finished with value: 0.8656255271166873 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 294, 'rf_max_depth': 11, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': None}. Best is trial 43 with value: 0.8656255271166873.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:20:07,338] Trial 44 finished with value: 0.8638753707924544 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 295, 'rf_max_depth': 13, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': None}. Best is trial 43 with value: 0.8656255271166873.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:20:12,846] Trial 45 finished with value: 0.820625572591123 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 297, 'rf_max_depth': 11, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': 'balanced'}. Best is trial 43 with value: 0.8656255271166873.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:20:17,928] Trial 46 finished with value: 0.863875417673316 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 281, 'rf_max_depth': 10, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': None}. Best is trial 43 with value: 0.8656255271166873.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:20:23,852] Trial 47 finished with value: 0.8640004020502688 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 300, 'rf_max_depth': 13, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': None}. Best is trial 43 with value: 0.8656255271166873.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2026-01-19 08:20:28,494] Trial 48 finished with value: 0.7955007124484533 and parameters: {'classifier': 'SVC', 'svc_C': 19.13091375096821, 'svc_kernel': 'rbf', 'svc_gamma': 'scale', 'svc_class_weight': 'balanced'}. Best is trial 43 with value: 0.8656255271166873.\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2026-01-19 08:20:36,035] Trial 49 finished with value: 0.8292509479075806 and parameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 286, 'rf_max_depth': 12, 'rf_min_samples_split': 6, 'rf_min_samples_leaf': 7, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': 'balanced_subsample'}. Best is trial 43 with value: 0.8656255271166873.\n"
     ]
    }
   ],
   "source": [
    "# Create a study and optimize it using CmaEsSampler\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial accuracy: 0.8656255271166873\n",
      "Best hyperparameters: {'classifier': 'RandomForestClassifier', 'rf_n_estimators': 294, 'rf_max_depth': 11, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 9, 'rf_bootstrap': True, 'rf_criterion': 'log_loss', 'rf_class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "# Print the best result\n",
    "print(f'Best trial accuracy= {study.best_trial.value}')\n",
    "print(f'Best hyperparameters= {study.best_trial.params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda': 9.923384480379253e-05,\n",
       " 'alpha': 1.2267677834901283e-07,\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 4,\n",
       " 'gamma': 1.146223408178716e-05,\n",
       " 'subsample': 0.5540225770928476,\n",
       " 'colsample_bytree': 0.697095234561352,\n",
       " 'eta': 0.011813113560208983,\n",
       " 'n_estimators': 206}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{**study.best_trial.params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForestClassifier using the best hyperparameters from Optuna\n",
    "best_model = RandomForestClassifier(**study.best_trial.params, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_classifier</th>\n",
       "      <th>params_rf_bootstrap</th>\n",
       "      <th>params_rf_class_weight</th>\n",
       "      <th>params_rf_criterion</th>\n",
       "      <th>params_rf_max_depth</th>\n",
       "      <th>params_rf_min_samples_leaf</th>\n",
       "      <th>params_rf_min_samples_split</th>\n",
       "      <th>params_rf_n_estimators</th>\n",
       "      <th>params_svc_C</th>\n",
       "      <th>params_svc_class_weight</th>\n",
       "      <th>params_svc_gamma</th>\n",
       "      <th>params_svc_kernel</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>2026-01-19 08:14:02.482833</td>\n",
       "      <td>2026-01-19 08:14:08.697594</td>\n",
       "      <td>0 days 00:00:06.214761</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.862876</td>\n",
       "      <td>2026-01-19 08:14:08.711704</td>\n",
       "      <td>2026-01-19 08:14:30.053736</td>\n",
       "      <td>0 days 00:00:21.342032</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.844875</td>\n",
       "      <td>2026-01-19 08:14:30.065067</td>\n",
       "      <td>2026-01-19 08:14:54.819377</td>\n",
       "      <td>0 days 00:00:24.754310</td>\n",
       "      <td>SVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.485777</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.863625</td>\n",
       "      <td>2026-01-19 08:14:54.823420</td>\n",
       "      <td>2026-01-19 08:15:12.510957</td>\n",
       "      <td>0 days 00:00:17.687537</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.804501</td>\n",
       "      <td>2026-01-19 08:15:12.515341</td>\n",
       "      <td>2026-01-19 08:15:31.456483</td>\n",
       "      <td>0 days 00:00:18.941142</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.821251</td>\n",
       "      <td>2026-01-19 08:15:31.466628</td>\n",
       "      <td>2026-01-19 08:15:55.571989</td>\n",
       "      <td>0 days 00:00:24.105361</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.862125</td>\n",
       "      <td>2026-01-19 08:15:55.577090</td>\n",
       "      <td>2026-01-19 08:16:00.937872</td>\n",
       "      <td>0 days 00:00:05.360782</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.722625</td>\n",
       "      <td>2026-01-19 08:16:00.941922</td>\n",
       "      <td>2026-01-19 08:16:08.452255</td>\n",
       "      <td>0 days 00:00:07.510333</td>\n",
       "      <td>SVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.526513</td>\n",
       "      <td>None</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.789251</td>\n",
       "      <td>2026-01-19 08:16:08.454285</td>\n",
       "      <td>2026-01-19 08:16:33.482019</td>\n",
       "      <td>0 days 00:00:25.027734</td>\n",
       "      <td>SVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.489651</td>\n",
       "      <td>balanced</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.844875</td>\n",
       "      <td>2026-01-19 08:16:33.482019</td>\n",
       "      <td>2026-01-19 08:16:43.073716</td>\n",
       "      <td>0 days 00:00:09.591697</td>\n",
       "      <td>SVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.114790</td>\n",
       "      <td>None</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.821126</td>\n",
       "      <td>2026-01-19 08:16:43.073716</td>\n",
       "      <td>2026-01-19 08:17:12.677066</td>\n",
       "      <td>0 days 00:00:29.603350</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.863250</td>\n",
       "      <td>2026-01-19 08:17:12.677066</td>\n",
       "      <td>2026-01-19 08:17:17.754772</td>\n",
       "      <td>0 days 00:00:05.077706</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>2026-01-19 08:17:17.754772</td>\n",
       "      <td>2026-01-19 08:17:20.665778</td>\n",
       "      <td>0 days 00:00:02.911006</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.862126</td>\n",
       "      <td>2026-01-19 08:17:20.665778</td>\n",
       "      <td>2026-01-19 08:17:23.481837</td>\n",
       "      <td>0 days 00:00:02.816059</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.864126</td>\n",
       "      <td>2026-01-19 08:17:23.481837</td>\n",
       "      <td>2026-01-19 08:17:28.325871</td>\n",
       "      <td>0 days 00:00:04.844034</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.813876</td>\n",
       "      <td>2026-01-19 08:17:28.341863</td>\n",
       "      <td>2026-01-19 08:17:31.682682</td>\n",
       "      <td>0 days 00:00:03.340819</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.862626</td>\n",
       "      <td>2026-01-19 08:17:31.682682</td>\n",
       "      <td>2026-01-19 08:17:36.888621</td>\n",
       "      <td>0 days 00:00:05.205939</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.864625</td>\n",
       "      <td>2026-01-19 08:17:36.888621</td>\n",
       "      <td>2026-01-19 08:17:43.573743</td>\n",
       "      <td>0 days 00:00:06.685122</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.837875</td>\n",
       "      <td>2026-01-19 08:17:43.575754</td>\n",
       "      <td>2026-01-19 08:17:55.514540</td>\n",
       "      <td>0 days 00:00:11.938786</td>\n",
       "      <td>SVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139540</td>\n",
       "      <td>balanced</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.864001</td>\n",
       "      <td>2026-01-19 08:17:55.530621</td>\n",
       "      <td>2026-01-19 08:18:04.836694</td>\n",
       "      <td>0 days 00:00:09.306073</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.824251</td>\n",
       "      <td>2026-01-19 08:18:04.840145</td>\n",
       "      <td>2026-01-19 08:18:13.209624</td>\n",
       "      <td>0 days 00:00:08.369479</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.864001</td>\n",
       "      <td>2026-01-19 08:18:13.209624</td>\n",
       "      <td>2026-01-19 08:18:21.825006</td>\n",
       "      <td>0 days 00:00:08.615382</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.863750</td>\n",
       "      <td>2026-01-19 08:18:21.825006</td>\n",
       "      <td>2026-01-19 08:18:32.937213</td>\n",
       "      <td>0 days 00:00:11.112207</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.859875</td>\n",
       "      <td>2026-01-19 08:18:32.937213</td>\n",
       "      <td>2026-01-19 08:18:39.120704</td>\n",
       "      <td>0 days 00:00:06.183491</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.860376</td>\n",
       "      <td>2026-01-19 08:18:39.120704</td>\n",
       "      <td>2026-01-19 08:18:47.780833</td>\n",
       "      <td>0 days 00:00:08.660129</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.863750</td>\n",
       "      <td>2026-01-19 08:18:47.780833</td>\n",
       "      <td>2026-01-19 08:18:49.732434</td>\n",
       "      <td>0 days 00:00:01.951601</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.839124</td>\n",
       "      <td>2026-01-19 08:18:49.732434</td>\n",
       "      <td>2026-01-19 08:18:52.813892</td>\n",
       "      <td>0 days 00:00:03.081458</td>\n",
       "      <td>SVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105125</td>\n",
       "      <td>balanced</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.859750</td>\n",
       "      <td>2026-01-19 08:18:52.813892</td>\n",
       "      <td>2026-01-19 08:18:55.367189</td>\n",
       "      <td>0 days 00:00:02.553297</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.820376</td>\n",
       "      <td>2026-01-19 08:18:55.367189</td>\n",
       "      <td>2026-01-19 08:18:59.044798</td>\n",
       "      <td>0 days 00:00:03.677609</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>2026-01-19 08:18:59.048343</td>\n",
       "      <td>2026-01-19 08:19:00.550490</td>\n",
       "      <td>0 days 00:00:01.502147</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.865125</td>\n",
       "      <td>2026-01-19 08:19:00.550490</td>\n",
       "      <td>2026-01-19 08:19:04.631659</td>\n",
       "      <td>0 days 00:00:04.081169</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>2026-01-19 08:19:04.631659</td>\n",
       "      <td>2026-01-19 08:19:08.814345</td>\n",
       "      <td>0 days 00:00:04.182686</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.865001</td>\n",
       "      <td>2026-01-19 08:19:08.815357</td>\n",
       "      <td>2026-01-19 08:19:13.514168</td>\n",
       "      <td>0 days 00:00:04.698811</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.864876</td>\n",
       "      <td>2026-01-19 08:19:13.514168</td>\n",
       "      <td>2026-01-19 08:19:17.780363</td>\n",
       "      <td>0 days 00:00:04.266195</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.863750</td>\n",
       "      <td>2026-01-19 08:19:17.793481</td>\n",
       "      <td>2026-01-19 08:19:22.662093</td>\n",
       "      <td>0 days 00:00:04.868612</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>2026-01-19 08:19:22.662093</td>\n",
       "      <td>2026-01-19 08:19:27.580468</td>\n",
       "      <td>0 days 00:00:04.918375</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.843876</td>\n",
       "      <td>2026-01-19 08:19:27.580468</td>\n",
       "      <td>2026-01-19 08:19:32.179701</td>\n",
       "      <td>0 days 00:00:04.599233</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.745125</td>\n",
       "      <td>2026-01-19 08:19:32.179701</td>\n",
       "      <td>2026-01-19 08:19:33.580304</td>\n",
       "      <td>0 days 00:00:01.400603</td>\n",
       "      <td>SVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.489989</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.865125</td>\n",
       "      <td>2026-01-19 08:19:33.580304</td>\n",
       "      <td>2026-01-19 08:19:37.619881</td>\n",
       "      <td>0 days 00:00:04.039577</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.865251</td>\n",
       "      <td>2026-01-19 08:19:37.619881</td>\n",
       "      <td>2026-01-19 08:19:42.997312</td>\n",
       "      <td>0 days 00:00:05.377431</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.785751</td>\n",
       "      <td>2026-01-19 08:19:42.997312</td>\n",
       "      <td>2026-01-19 08:19:46.830605</td>\n",
       "      <td>0 days 00:00:03.833293</td>\n",
       "      <td>SVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704843</td>\n",
       "      <td>balanced</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.865125</td>\n",
       "      <td>2026-01-19 08:19:46.830605</td>\n",
       "      <td>2026-01-19 08:19:51.798014</td>\n",
       "      <td>0 days 00:00:04.967409</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.865501</td>\n",
       "      <td>2026-01-19 08:19:51.812118</td>\n",
       "      <td>2026-01-19 08:19:57.016680</td>\n",
       "      <td>0 days 00:00:05.204562</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.865626</td>\n",
       "      <td>2026-01-19 08:19:57.018765</td>\n",
       "      <td>2026-01-19 08:20:02.049704</td>\n",
       "      <td>0 days 00:00:05.030939</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.863875</td>\n",
       "      <td>2026-01-19 08:20:02.051690</td>\n",
       "      <td>2026-01-19 08:20:07.338391</td>\n",
       "      <td>0 days 00:00:05.286701</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.820626</td>\n",
       "      <td>2026-01-19 08:20:07.338391</td>\n",
       "      <td>2026-01-19 08:20:12.845021</td>\n",
       "      <td>0 days 00:00:05.506630</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.863875</td>\n",
       "      <td>2026-01-19 08:20:12.847025</td>\n",
       "      <td>2026-01-19 08:20:17.928103</td>\n",
       "      <td>0 days 00:00:05.081078</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>2026-01-19 08:20:17.928103</td>\n",
       "      <td>2026-01-19 08:20:23.852831</td>\n",
       "      <td>0 days 00:00:05.924728</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.795501</td>\n",
       "      <td>2026-01-19 08:20:23.853830</td>\n",
       "      <td>2026-01-19 08:20:28.494476</td>\n",
       "      <td>0 days 00:00:04.640646</td>\n",
       "      <td>SVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.130914</td>\n",
       "      <td>balanced</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.829251</td>\n",
       "      <td>2026-01-19 08:20:28.494476</td>\n",
       "      <td>2026-01-19 08:20:36.035636</td>\n",
       "      <td>0 days 00:00:07.541160</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.796875 2026-01-19 08:14:02.482833 2026-01-19 08:14:08.697594   \n",
       "1        1  0.862876 2026-01-19 08:14:08.711704 2026-01-19 08:14:30.053736   \n",
       "2        2  0.844875 2026-01-19 08:14:30.065067 2026-01-19 08:14:54.819377   \n",
       "3        3  0.863625 2026-01-19 08:14:54.823420 2026-01-19 08:15:12.510957   \n",
       "4        4  0.804501 2026-01-19 08:15:12.515341 2026-01-19 08:15:31.456483   \n",
       "5        5  0.821251 2026-01-19 08:15:31.466628 2026-01-19 08:15:55.571989   \n",
       "6        6  0.862125 2026-01-19 08:15:55.577090 2026-01-19 08:16:00.937872   \n",
       "7        7  0.722625 2026-01-19 08:16:00.941922 2026-01-19 08:16:08.452255   \n",
       "8        8  0.789251 2026-01-19 08:16:08.454285 2026-01-19 08:16:33.482019   \n",
       "9        9  0.844875 2026-01-19 08:16:33.482019 2026-01-19 08:16:43.073716   \n",
       "10      10  0.821126 2026-01-19 08:16:43.073716 2026-01-19 08:17:12.677066   \n",
       "11      11  0.863250 2026-01-19 08:17:12.677066 2026-01-19 08:17:17.754772   \n",
       "12      12  0.864000 2026-01-19 08:17:17.754772 2026-01-19 08:17:20.665778   \n",
       "13      13  0.862126 2026-01-19 08:17:20.665778 2026-01-19 08:17:23.481837   \n",
       "14      14  0.864126 2026-01-19 08:17:23.481837 2026-01-19 08:17:28.325871   \n",
       "15      15  0.813876 2026-01-19 08:17:28.341863 2026-01-19 08:17:31.682682   \n",
       "16      16  0.862626 2026-01-19 08:17:31.682682 2026-01-19 08:17:36.888621   \n",
       "17      17  0.864625 2026-01-19 08:17:36.888621 2026-01-19 08:17:43.573743   \n",
       "18      18  0.837875 2026-01-19 08:17:43.575754 2026-01-19 08:17:55.514540   \n",
       "19      19  0.864001 2026-01-19 08:17:55.530621 2026-01-19 08:18:04.836694   \n",
       "20      20  0.824251 2026-01-19 08:18:04.840145 2026-01-19 08:18:13.209624   \n",
       "21      21  0.864001 2026-01-19 08:18:13.209624 2026-01-19 08:18:21.825006   \n",
       "22      22  0.863750 2026-01-19 08:18:21.825006 2026-01-19 08:18:32.937213   \n",
       "23      23  0.859875 2026-01-19 08:18:32.937213 2026-01-19 08:18:39.120704   \n",
       "24      24  0.860376 2026-01-19 08:18:39.120704 2026-01-19 08:18:47.780833   \n",
       "25      25  0.863750 2026-01-19 08:18:47.780833 2026-01-19 08:18:49.732434   \n",
       "26      26  0.839124 2026-01-19 08:18:49.732434 2026-01-19 08:18:52.813892   \n",
       "27      27  0.859750 2026-01-19 08:18:52.813892 2026-01-19 08:18:55.367189   \n",
       "28      28  0.820376 2026-01-19 08:18:55.367189 2026-01-19 08:18:59.044798   \n",
       "29      29  0.799000 2026-01-19 08:18:59.048343 2026-01-19 08:19:00.550490   \n",
       "30      30  0.865125 2026-01-19 08:19:00.550490 2026-01-19 08:19:04.631659   \n",
       "31      31  0.865000 2026-01-19 08:19:04.631659 2026-01-19 08:19:08.814345   \n",
       "32      32  0.865001 2026-01-19 08:19:08.815357 2026-01-19 08:19:13.514168   \n",
       "33      33  0.864876 2026-01-19 08:19:13.514168 2026-01-19 08:19:17.780363   \n",
       "34      34  0.863750 2026-01-19 08:19:17.793481 2026-01-19 08:19:22.662093   \n",
       "35      35  0.864501 2026-01-19 08:19:22.662093 2026-01-19 08:19:27.580468   \n",
       "36      36  0.843876 2026-01-19 08:19:27.580468 2026-01-19 08:19:32.179701   \n",
       "37      37  0.745125 2026-01-19 08:19:32.179701 2026-01-19 08:19:33.580304   \n",
       "38      38  0.865125 2026-01-19 08:19:33.580304 2026-01-19 08:19:37.619881   \n",
       "39      39  0.865251 2026-01-19 08:19:37.619881 2026-01-19 08:19:42.997312   \n",
       "40      40  0.785751 2026-01-19 08:19:42.997312 2026-01-19 08:19:46.830605   \n",
       "41      41  0.865125 2026-01-19 08:19:46.830605 2026-01-19 08:19:51.798014   \n",
       "42      42  0.865501 2026-01-19 08:19:51.812118 2026-01-19 08:19:57.016680   \n",
       "43      43  0.865626 2026-01-19 08:19:57.018765 2026-01-19 08:20:02.049704   \n",
       "44      44  0.863875 2026-01-19 08:20:02.051690 2026-01-19 08:20:07.338391   \n",
       "45      45  0.820626 2026-01-19 08:20:07.338391 2026-01-19 08:20:12.845021   \n",
       "46      46  0.863875 2026-01-19 08:20:12.847025 2026-01-19 08:20:17.928103   \n",
       "47      47  0.864000 2026-01-19 08:20:17.928103 2026-01-19 08:20:23.852831   \n",
       "48      48  0.795501 2026-01-19 08:20:23.853830 2026-01-19 08:20:28.494476   \n",
       "49      49  0.829251 2026-01-19 08:20:28.494476 2026-01-19 08:20:36.035636   \n",
       "\n",
       "                 duration       params_classifier params_rf_bootstrap  \\\n",
       "0  0 days 00:00:06.214761  RandomForestClassifier               False   \n",
       "1  0 days 00:00:21.342032  RandomForestClassifier                True   \n",
       "2  0 days 00:00:24.754310                     SVC                 NaN   \n",
       "3  0 days 00:00:17.687537  RandomForestClassifier                True   \n",
       "4  0 days 00:00:18.941142  RandomForestClassifier               False   \n",
       "5  0 days 00:00:24.105361  RandomForestClassifier               False   \n",
       "6  0 days 00:00:05.360782  RandomForestClassifier                True   \n",
       "7  0 days 00:00:07.510333                     SVC                 NaN   \n",
       "8  0 days 00:00:25.027734                     SVC                 NaN   \n",
       "9  0 days 00:00:09.591697                     SVC                 NaN   \n",
       "10 0 days 00:00:29.603350  RandomForestClassifier                True   \n",
       "11 0 days 00:00:05.077706  RandomForestClassifier                True   \n",
       "12 0 days 00:00:02.911006  RandomForestClassifier                True   \n",
       "13 0 days 00:00:02.816059  RandomForestClassifier                True   \n",
       "14 0 days 00:00:04.844034  RandomForestClassifier                True   \n",
       "15 0 days 00:00:03.340819  RandomForestClassifier                True   \n",
       "16 0 days 00:00:05.205939  RandomForestClassifier                True   \n",
       "17 0 days 00:00:06.685122  RandomForestClassifier                True   \n",
       "18 0 days 00:00:11.938786                     SVC                 NaN   \n",
       "19 0 days 00:00:09.306073  RandomForestClassifier               False   \n",
       "20 0 days 00:00:08.369479  RandomForestClassifier                True   \n",
       "21 0 days 00:00:08.615382  RandomForestClassifier               False   \n",
       "22 0 days 00:00:11.112207  RandomForestClassifier               False   \n",
       "23 0 days 00:00:06.183491  RandomForestClassifier               False   \n",
       "24 0 days 00:00:08.660129  RandomForestClassifier               False   \n",
       "25 0 days 00:00:01.951601  RandomForestClassifier                True   \n",
       "26 0 days 00:00:03.081458                     SVC                 NaN   \n",
       "27 0 days 00:00:02.553297  RandomForestClassifier               False   \n",
       "28 0 days 00:00:03.677609  RandomForestClassifier                True   \n",
       "29 0 days 00:00:01.502147  RandomForestClassifier               False   \n",
       "30 0 days 00:00:04.081169  RandomForestClassifier                True   \n",
       "31 0 days 00:00:04.182686  RandomForestClassifier                True   \n",
       "32 0 days 00:00:04.698811  RandomForestClassifier                True   \n",
       "33 0 days 00:00:04.266195  RandomForestClassifier                True   \n",
       "34 0 days 00:00:04.868612  RandomForestClassifier                True   \n",
       "35 0 days 00:00:04.918375  RandomForestClassifier                True   \n",
       "36 0 days 00:00:04.599233  RandomForestClassifier                True   \n",
       "37 0 days 00:00:01.400603                     SVC                 NaN   \n",
       "38 0 days 00:00:04.039577  RandomForestClassifier                True   \n",
       "39 0 days 00:00:05.377431  RandomForestClassifier                True   \n",
       "40 0 days 00:00:03.833293                     SVC                 NaN   \n",
       "41 0 days 00:00:04.967409  RandomForestClassifier                True   \n",
       "42 0 days 00:00:05.204562  RandomForestClassifier                True   \n",
       "43 0 days 00:00:05.030939  RandomForestClassifier                True   \n",
       "44 0 days 00:00:05.286701  RandomForestClassifier                True   \n",
       "45 0 days 00:00:05.506630  RandomForestClassifier                True   \n",
       "46 0 days 00:00:05.081078  RandomForestClassifier                True   \n",
       "47 0 days 00:00:05.924728  RandomForestClassifier                True   \n",
       "48 0 days 00:00:04.640646                     SVC                 NaN   \n",
       "49 0 days 00:00:07.541160  RandomForestClassifier                True   \n",
       "\n",
       "   params_rf_class_weight params_rf_criterion  params_rf_max_depth  \\\n",
       "0                balanced            log_loss                  5.0   \n",
       "1                    None            log_loss                 17.0   \n",
       "2                     NaN                 NaN                  NaN   \n",
       "3                    None             entropy                 18.0   \n",
       "4                balanced            log_loss                  3.0   \n",
       "5                balanced                gini                 19.0   \n",
       "6                    None             entropy                 13.0   \n",
       "7                     NaN                 NaN                  NaN   \n",
       "8                     NaN                 NaN                  NaN   \n",
       "9                     NaN                 NaN                  NaN   \n",
       "10     balanced_subsample             entropy                 12.0   \n",
       "11                   None            log_loss                 20.0   \n",
       "12                   None             entropy                 20.0   \n",
       "13                   None             entropy                 16.0   \n",
       "14                   None             entropy                  8.0   \n",
       "15     balanced_subsample             entropy                  8.0   \n",
       "16                   None                gini                  8.0   \n",
       "17                   None             entropy                  9.0   \n",
       "18                    NaN                 NaN                  NaN   \n",
       "19                   None             entropy                  9.0   \n",
       "20     balanced_subsample             entropy                 10.0   \n",
       "21                   None             entropy                  8.0   \n",
       "22                   None             entropy                 10.0   \n",
       "23                   None             entropy                  6.0   \n",
       "24                   None                gini                 14.0   \n",
       "25                   None             entropy                 10.0   \n",
       "26                    NaN                 NaN                  NaN   \n",
       "27                   None             entropy                  6.0   \n",
       "28     balanced_subsample             entropy                  9.0   \n",
       "29               balanced                gini                  6.0   \n",
       "30                   None             entropy                 11.0   \n",
       "31                   None             entropy                 11.0   \n",
       "32                   None             entropy                 12.0   \n",
       "33                   None             entropy                 14.0   \n",
       "34                   None             entropy                 15.0   \n",
       "35                   None             entropy                 12.0   \n",
       "36               balanced            log_loss                 14.0   \n",
       "37                    NaN                 NaN                  NaN   \n",
       "38                   None             entropy                 11.0   \n",
       "39                   None            log_loss                 11.0   \n",
       "40                    NaN                 NaN                  NaN   \n",
       "41                   None            log_loss                 11.0   \n",
       "42                   None            log_loss                 11.0   \n",
       "43                   None            log_loss                 11.0   \n",
       "44                   None            log_loss                 13.0   \n",
       "45               balanced            log_loss                 11.0   \n",
       "46                   None            log_loss                 10.0   \n",
       "47                   None            log_loss                 13.0   \n",
       "48                    NaN                 NaN                  NaN   \n",
       "49     balanced_subsample            log_loss                 12.0   \n",
       "\n",
       "    params_rf_min_samples_leaf  params_rf_min_samples_split  \\\n",
       "0                          2.0                          2.0   \n",
       "1                          6.0                          4.0   \n",
       "2                          NaN                          NaN   \n",
       "3                          9.0                          2.0   \n",
       "4                          2.0                          9.0   \n",
       "5                          5.0                          5.0   \n",
       "6                          7.0                          8.0   \n",
       "7                          NaN                          NaN   \n",
       "8                          NaN                          NaN   \n",
       "9                          NaN                          NaN   \n",
       "10                        10.0                          2.0   \n",
       "11                         9.0                          4.0   \n",
       "12                        10.0                          4.0   \n",
       "13                         8.0                          2.0   \n",
       "14                        10.0                          6.0   \n",
       "15                        10.0                          7.0   \n",
       "16                         4.0                          6.0   \n",
       "17                         8.0                         10.0   \n",
       "18                         NaN                          NaN   \n",
       "19                         8.0                         10.0   \n",
       "20                         7.0                          7.0   \n",
       "21                         8.0                         10.0   \n",
       "22                         8.0                         10.0   \n",
       "23                         9.0                          9.0   \n",
       "24                         6.0                          9.0   \n",
       "25                         7.0                          7.0   \n",
       "26                         NaN                          NaN   \n",
       "27                         4.0                          8.0   \n",
       "28                         9.0                         10.0   \n",
       "29                         8.0                          6.0   \n",
       "30                        10.0                          8.0   \n",
       "31                        10.0                          8.0   \n",
       "32                        10.0                          8.0   \n",
       "33                        10.0                          8.0   \n",
       "34                        10.0                          8.0   \n",
       "35                         9.0                          8.0   \n",
       "36                         1.0                          9.0   \n",
       "37                         NaN                          NaN   \n",
       "38                        10.0                          7.0   \n",
       "39                         9.0                          7.0   \n",
       "40                         NaN                          NaN   \n",
       "41                        10.0                          7.0   \n",
       "42                         9.0                          7.0   \n",
       "43                         9.0                          7.0   \n",
       "44                         9.0                          7.0   \n",
       "45                         9.0                          5.0   \n",
       "46                         9.0                          7.0   \n",
       "47                         9.0                          5.0   \n",
       "48                         NaN                          NaN   \n",
       "49                         7.0                          6.0   \n",
       "\n",
       "    params_rf_n_estimators  params_svc_C params_svc_class_weight  \\\n",
       "0                    141.0           NaN                     NaN   \n",
       "1                    187.0           NaN                     NaN   \n",
       "2                      NaN      1.485777                    None   \n",
       "3                    108.0           NaN                     NaN   \n",
       "4                    229.0           NaN                     NaN   \n",
       "5                    171.0           NaN                     NaN   \n",
       "6                     80.0           NaN                     NaN   \n",
       "7                      NaN      3.526513                    None   \n",
       "8                      NaN     41.489651                balanced   \n",
       "9                      NaN      7.114790                    None   \n",
       "10                   291.0           NaN                     NaN   \n",
       "11                    89.0           NaN                     NaN   \n",
       "12                    56.0           NaN                     NaN   \n",
       "13                    58.0           NaN                     NaN   \n",
       "14                   114.0           NaN                     NaN   \n",
       "15                    50.0           NaN                     NaN   \n",
       "16                   128.0           NaN                     NaN   \n",
       "17                   143.0           NaN                     NaN   \n",
       "18                     NaN      0.139540                balanced   \n",
       "19                   181.0           NaN                     NaN   \n",
       "20                   143.0           NaN                     NaN   \n",
       "21                   186.0           NaN                     NaN   \n",
       "22                   228.0           NaN                     NaN   \n",
       "23                   167.0           NaN                     NaN   \n",
       "24                   218.0           NaN                     NaN   \n",
       "25                   118.0           NaN                     NaN   \n",
       "26                     NaN      0.105125                balanced   \n",
       "27                   152.0           NaN                     NaN   \n",
       "28                   197.0           NaN                     NaN   \n",
       "29                   101.0           NaN                     NaN   \n",
       "30                   259.0           NaN                     NaN   \n",
       "31                   258.0           NaN                     NaN   \n",
       "32                   270.0           NaN                     NaN   \n",
       "33                   272.0           NaN                     NaN   \n",
       "34                   277.0           NaN                     NaN   \n",
       "35                   256.0           NaN                     NaN   \n",
       "36                   257.0           NaN                     NaN   \n",
       "37                     NaN     70.489989                    None   \n",
       "38                   256.0           NaN                     NaN   \n",
       "39                   298.0           NaN                     NaN   \n",
       "40                     NaN      0.704843                balanced   \n",
       "41                   299.0           NaN                     NaN   \n",
       "42                   300.0           NaN                     NaN   \n",
       "43                   294.0           NaN                     NaN   \n",
       "44                   295.0           NaN                     NaN   \n",
       "45                   297.0           NaN                     NaN   \n",
       "46                   281.0           NaN                     NaN   \n",
       "47                   300.0           NaN                     NaN   \n",
       "48                     NaN     19.130914                balanced   \n",
       "49                   286.0           NaN                     NaN   \n",
       "\n",
       "   params_svc_gamma params_svc_kernel     state  \n",
       "0               NaN               NaN  COMPLETE  \n",
       "1               NaN               NaN  COMPLETE  \n",
       "2              auto            linear  COMPLETE  \n",
       "3               NaN               NaN  COMPLETE  \n",
       "4               NaN               NaN  COMPLETE  \n",
       "5               NaN               NaN  COMPLETE  \n",
       "6               NaN               NaN  COMPLETE  \n",
       "7             scale           sigmoid  COMPLETE  \n",
       "8             scale               rbf  COMPLETE  \n",
       "9             scale            linear  COMPLETE  \n",
       "10              NaN               NaN  COMPLETE  \n",
       "11              NaN               NaN  COMPLETE  \n",
       "12              NaN               NaN  COMPLETE  \n",
       "13              NaN               NaN  COMPLETE  \n",
       "14              NaN               NaN  COMPLETE  \n",
       "15              NaN               NaN  COMPLETE  \n",
       "16              NaN               NaN  COMPLETE  \n",
       "17              NaN               NaN  COMPLETE  \n",
       "18             auto              poly  COMPLETE  \n",
       "19              NaN               NaN  COMPLETE  \n",
       "20              NaN               NaN  COMPLETE  \n",
       "21              NaN               NaN  COMPLETE  \n",
       "22              NaN               NaN  COMPLETE  \n",
       "23              NaN               NaN  COMPLETE  \n",
       "24              NaN               NaN  COMPLETE  \n",
       "25              NaN               NaN  COMPLETE  \n",
       "26             auto              poly  COMPLETE  \n",
       "27              NaN               NaN  COMPLETE  \n",
       "28              NaN               NaN  COMPLETE  \n",
       "29              NaN               NaN  COMPLETE  \n",
       "30              NaN               NaN  COMPLETE  \n",
       "31              NaN               NaN  COMPLETE  \n",
       "32              NaN               NaN  COMPLETE  \n",
       "33              NaN               NaN  COMPLETE  \n",
       "34              NaN               NaN  COMPLETE  \n",
       "35              NaN               NaN  COMPLETE  \n",
       "36              NaN               NaN  COMPLETE  \n",
       "37             auto           sigmoid  COMPLETE  \n",
       "38              NaN               NaN  COMPLETE  \n",
       "39              NaN               NaN  COMPLETE  \n",
       "40            scale               rbf  COMPLETE  \n",
       "41              NaN               NaN  COMPLETE  \n",
       "42              NaN               NaN  COMPLETE  \n",
       "43              NaN               NaN  COMPLETE  \n",
       "44              NaN               NaN  COMPLETE  \n",
       "45              NaN               NaN  COMPLETE  \n",
       "46              NaN               NaN  COMPLETE  \n",
       "47              NaN               NaN  COMPLETE  \n",
       "48            scale               rbf  COMPLETE  \n",
       "49              NaN               NaN  COMPLETE  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "params_classifier\n",
       "RandomForestClassifier    41\n",
       "SVC                        9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()['params_classifier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def objective(trial)=\n",
    "    param = {\n",
    "        'verbosity'= 0,\n",
    "        'objective'= 'binary=logistic',\n",
    "        'eval_metric'= 'logloss',\n",
    "        'booster'= 'gbtree',\n",
    "        'tree_method'= 'hist',  # Faster training\n",
    "\n",
    "        # Regularization\n",
    "        'lambda'= trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
    "        'alpha'= trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n",
    "\n",
    "        # Tree structure\n",
    "        'max_depth'= trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight'= trial.suggest_int('min_child_weight', 1, 20),\n",
    "        'gamma'= trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "\n",
    "        # Sampling (stochastic gradient boosting)\n",
    "        'subsample'= trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree'= trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "\n",
    "        # Learning rate\n",
    "        'eta'= trial.suggest_float('eta', 0.01, 0.3, log=True),\n",
    "        'n_estimators'= trial.suggest_int('n_estimators', 100, 500),\n",
    "\n",
    "        # Class imbalance - use scale_pos_weight instead of class_weight\n",
    "        'scale_pos_weight'= (y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**param, random_state=42)\n",
    "\n",
    "    # Use CV with F1 since you have class imbalance\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial accuracy: 0.620883440700027\n",
      "Best hyperparameters: {'lambda': 9.923384480379253e-05, 'alpha': 1.2267677834901283e-07, 'max_depth': 9, 'min_child_weight': 4, 'gamma': 1.146223408178716e-05, 'subsample': 0.5540225770928476, 'colsample_bytree': 0.697095234561352, 'eta': 0.011813113560208983, 'n_estimators': 206}\n"
     ]
    }
   ],
   "source": [
    "# Print the best result\n",
    "print(f'Best trial accuracy= {study.best_trial.value}')\n",
    "print(f'Best hyperparameters= {study.best_trial.params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying RandomForest\n",
    "model = RandomForestClassifier(n_estimators= 294, max_depth= 11, min_samples_split= 7, min_samples_leaf= 9, bootstrap= True, criterion= 'log_loss', class_weight= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_depth=11, min_samples_leaf=9,\n",
       "                       min_samples_split=7, n_estimators=294)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">294</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.<br>Note: This parameter is tree-specific.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;log_loss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">11</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D%22sqrt%22\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.accuracy_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=class_weight,-%7B%22balanced%22%2C%20%22balanced_subsample%22%7D%2C%20dict%20or%20list%20of%20dicts%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>The \"balanced_subsample\" mode is the same as \"balanced\" except that<br>weights are computed based on the bootstrap sample for every tree<br>grown.<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-3');</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='log_loss', max_depth=11, min_samples_leaf=9,\n",
       "                       min_samples_split=7, n_estimators=294)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], shape=(2000,))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.864"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1541,   52],\n",
       "       [ 220,  187]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      1593\n",
      "           1       0.78      0.46      0.58       407\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.83      0.71      0.75      2000\n",
      "weighted avg       0.86      0.86      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = LogisticRegression(l1_ratio=0.5,class_weight='balanced',solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, l1_ratio=0.5, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;saga&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', l1_ratio=0.5, solver='saga')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1289,  304],\n",
       "       [ 108,  299]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      1593\n",
      "           1       0.50      0.73      0.59       407\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.71      0.77      0.73      2000\n",
      "weighted avg       0.84      0.79      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              feature_weights=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=None, num_parallel_tree=None, ...)\n",
      "Train performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      6370\n",
      "           1       0.95      0.76      0.84      1630\n",
      "\n",
      "    accuracy                           0.94      8000\n",
      "   macro avg       0.95      0.87      0.90      8000\n",
      "weighted avg       0.94      0.94      0.94      8000\n",
      "\n",
      "Test performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1593\n",
      "           1       0.68      0.50      0.58       407\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.78      0.72      0.74      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n",
      "Roc_auc score\n",
      "-------------------------------------------------------\n",
      "0.7217109251007556\n",
      "\n",
      "Confusion matrix\n",
      "-------------------------------------------------------\n",
      "[[1497   96]\n",
      " [ 202  205]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(random_state=123)\n",
    "model.fit(X_train, y_train)\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "\n",
    "print(model)\n",
    "print('Train performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_train, y_train_hat))\n",
    "\n",
    "print('Test performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_test, y_test_hat))\n",
    "\n",
    "print('Roc_auc score')\n",
    "print('-------------------------------------------------------')\n",
    "print(roc_auc_score(y_test, y_test_hat))\n",
    "print('')\n",
    "\n",
    "print('Confusion matrix')\n",
    "print('-------------------------------------------------------')\n",
    "print(confusion_matrix(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hmadarw\\Learnings\\DataScience\\Projects\\CustomerChurn\\venv\\Lib\\site-packages\\sklearn\\base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(random_state=123)\n",
      "Train performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6370\n",
      "           1       1.00      1.00      1.00      1630\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       1.00      1.00      1.00      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Test performance\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      1593\n",
      "           1       0.58      0.49      0.53       407\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.73      0.70      0.71      2000\n",
      "weighted avg       0.82      0.82      0.82      2000\n",
      "\n",
      "Roc_auc score\n",
      "-------------------------------------------------------\n",
      "0.7011032604252944\n",
      "\n",
      "Confusion matrix\n",
      "-------------------------------------------------------\n",
      "[[1447  146]\n",
      " [ 206  201]]\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model = ExtraTreesClassifier(random_state=123)\n",
    "model.fit(X_train, y_train)\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "\n",
    "print(model)\n",
    "print('Train performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_train, y_train_hat))\n",
    "\n",
    "print('Test performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_test, y_test_hat))\n",
    "\n",
    "print('Roc_auc score')\n",
    "print('-------------------------------------------------------')\n",
    "print(roc_auc_score(y_test, y_test_hat))\n",
    "print('')\n",
    "\n",
    "print('Confusion matrix')\n",
    "print('-------------------------------------------------------')\n",
    "print(confusion_matrix(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = GridSearchCV(RandomForestClassifier(n_jobs=-1), params, n_jobs=-1, cv=KFold(n_splits=3), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
